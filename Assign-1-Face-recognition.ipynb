{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46c90c7-4709-4601-b59b-2cc6ef4f9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a8288-eca5-449c-84fc-656951dd4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face_dataset(images_dir):\n",
    "    faces = []\n",
    "    names = []\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "    for filename in os.listdir(images_dir):\n",
    "        name = filename.split(\".\")[0]\n",
    "        \n",
    "        # load image\n",
    "        image_path = os.path.join(images_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # convert image to gray scale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # detect face position\n",
    "        face_pos = face_classifier.detectMultiScale(image, minSize=(40, 40))\n",
    "        for (x, y, w, h) in face_pos:\n",
    "            # crop image to face size\n",
    "            image = image[y:y+h, x:x+w]\n",
    "            \n",
    "        faces.append(image)\n",
    "        names.append(name)\n",
    "    \n",
    "    # convert lists to NumPy arrays\n",
    "    faces = np.array(faces, dtype=\"object\")\n",
    "    names = np.array(names)\n",
    "    \n",
    "    return faces, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognizer_LBPH(trainX, trainY):\n",
    "    # train recognizer\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.train(trainX, trainY)\n",
    "    return recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_LBPH(recognizer, testX, testY):\n",
    "    predictions = []\n",
    "    predicted_names = []\n",
    "    confidence = []\n",
    "    \n",
    "    for face in testX:\n",
    "        # get prediction and confidence\n",
    "        predicted_name, confid = recognizer.predict(face)\n",
    "        predictions.append(predicted_name)\n",
    "        # convert integer prediction back to string\n",
    "        predicted_name = le.inverse_transform([predicted_name])[0]\n",
    "        predicted_names.append(predicted_name)\n",
    "        confidence.append(confid)\n",
    "    \n",
    "    # show classification report\n",
    "    print(\"Classification report:\\n\\n\", classification_report(testY, predictions, target_names=le.classes_))\n",
    "    return predicted_names, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ff67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(testX, testY, predicted_names, confidence):\n",
    "    rows = math.ceil(len(testX) / 3)\n",
    "    columns = 8\n",
    "    fig = plt.figure(figsize=(16, 3*rows))\n",
    "\n",
    "    i = 0\n",
    "    count = 1\n",
    "    for image in testX:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        actual_name = le.classes_[testY[i]]\n",
    "        # plot image\n",
    "        fig.add_subplot(rows, columns, count)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        count += 1\n",
    "        \n",
    "        # add text\n",
    "        fig.add_subplot(rows, columns, count)\n",
    "        if predicted_names[i] == actual_name:\n",
    "            plt.text(0, 0.6, \"predicted: \" + predicted_names[i], color=\"green\")\n",
    "        else:\n",
    "            plt.text(0, 0.6, \"predicted: \" + predicted_names[i], color=\"red\")\n",
    "        plt.text(0, 0.5, \"actual: \" + actual_name)\n",
    "        # lower confidence number, more confident prediction \n",
    "        plt.text(0, 0.4, \"confidence: \" + str(round(confidence[i], 2)))\n",
    "        plt.axis(\"off\")\n",
    "        count += 1\n",
    "        i += 1\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"C:\\\\Users\\\\cwqka\\\\Downloads\\\\EE4208 Intelligent Systems Design\\\\Assignment 1\\\\Images\"\n",
    "\n",
    "# load face dataset\n",
    "faces, names = load_face_dataset(images_dir)\n",
    "# encode the names as integers\n",
    "le = LabelEncoder()\n",
    "names_int = le.fit_transform(names)\n",
    "# split dataset\n",
    "(trainX, testX, trainY, testY) = train_test_split(faces, names_int, test_size=0.25, stratify=names_int, random_state=42)\n",
    "\n",
    "# train LBPH model\n",
    "recognizer = recognizer_LBPH(trainX, trainY)\n",
    "# predict\n",
    "predicted_names, confidence = prediction_LBPH(recognizer, testX, testY)\n",
    "# display test images with predictions\n",
    "display_predictions(testX, testY, predicted_names, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270c15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
